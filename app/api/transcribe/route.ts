// Archivo: app/api/transcribe/route.ts

import { NextResponse } from "next/server"
import { openai } from "@ai-sdk/openai"

// La API Key se verifica autom√°ticamente por la librer√≠a,
// pero es crucial que est√© en tus variables de entorno de Vercel.

const ai = openai()

export async function POST(req: Request) {
  try {
    const formData = await req.formData()
    const file = formData.get("audio") as File | null

    if (!file) {
      console.error("API Error: No se recibi√≥ ning√∫n archivo de audio.")
      return NextResponse.json({ error: "No se proporcion√≥ ning√∫n archivo de audio." }, { status: 400 })
    }

    console.log("üé§ Audio recibido. Enviando a OpenAI Whisper...")

    // Llamada a la API simplificada para m√°xima compatibilidad
    // Usamos 'whisper-1' que es el m√°s flexible.
    // No especificamos 'response_format' para que use el default ('json'), que es seguro.
    const transcription = await ai.transcribe({
      model: "whisper-1",
      audio: file,
    })

    console.log("üìù Transcripci√≥n recibida de OpenAI:", transcription.text)

    // Devolvemos el texto transcrito. La respuesta de la librer√≠a ya nos da el '.text'.
    return NextResponse.json({ transcription: transcription.text })
  } catch (error) {
    // Mejoramos el log para ver el error espec√≠fico de OpenAI si lo hubiera
    console.error("‚ùå Error completo en la API de transcripci√≥n:", error)
    return NextResponse.json({ error: "Error interno al procesar la transcripci√≥n." }, { status: 500 })
  }
}
